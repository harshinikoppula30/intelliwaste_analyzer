{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshinikoppula30/intelliwaste_analyzer/blob/main/intelliwaste.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWp9FoDagjHF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/Garbage_Classification_Project/Garbage-Classification-System\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LL2-VNXej7Q1"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNTjM9JN51rV"
      },
      "outputs": [],
      "source": [
        "!ls /content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-biEwfdluxH"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# ‚úÖ Step 1: Create ImageDataGenerator with validation split\n",
        "gen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    brightness_range=(0.5, 1.5),\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.2  # üëà 80% train, 20% val\n",
        ")\n",
        "\n",
        "# ‚úÖ Step 2: Training data (80%)\n",
        "train_data = gen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Garbage_Classification_Project/Garbage-Classification-System/full_garbage_dataset/',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    seed=42,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# ‚úÖ Step 3: Validation data (20%)\n",
        "val_data = gen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Garbage_Classification_Project/Garbage-Classification-System/full_garbage_dataset/',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    seed=42,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFl_-unQluoA"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "vgg16 = VGG16(input_shape=(224, 224, 3), weights='imagenet', include_top=False)\n",
        "\n",
        "# Optionally fine-tune last 4 layers\n",
        "for layer in vgg16.layers[:-4]:\n",
        "    layer.trainable = False\n",
        "for layer in vgg16.layers[-4:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Build custom head\n",
        "x = layers.GlobalAveragePooling2D()(vgg16.output)\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "prediction = layers.Dense(12, activation='softmax')(x)\n",
        "\n",
        "# Create model\n",
        "model = models.Model(inputs=vgg16.input, outputs=prediction)\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4s3BHRc6Vnz"
      },
      "outputs": [],
      "source": [
        "result = model.fit(\n",
        "    train_data,\n",
        "    validation_data=val_data,               # Keep 20% for validation\n",
        "    epochs=15,                              # üëâ Train for only 15 epochs\n",
        "    steps_per_epoch=len(train_data),\n",
        "    validation_steps=len(val_data),\n",
        "    verbose=1\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qu-p0wPoVR08"
      },
      "outputs": [],
      "source": [
        "# Save your trained model to Google Drive\n",
        "model.save(\"/content/drive/MyDrive/waste_classifier_full_vgg16.keras\")\n",
        "print(\"‚úÖ Model saved successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0Ce6cHJVUWc"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(\"/content/drive/MyDrive/waste_classifier_full_vgg16.keras\")\n",
        "print(\"‚úÖ Model loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AA2b2xJBVYZt"
      },
      "outputs": [],
      "source": [
        "output_class = [\n",
        "    \"battery\", \"biological\", \"brown-glass\", \"cardboard\", \"clothes\", \"green-glass\",\n",
        "    \"metal\", \"paper\", \"plastic\", \"shoes\", \"trash\", \"white-glass\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thBwBUlrml_l"
      },
      "outputs": [],
      "source": [
        "def waste_prediction(new_image):\n",
        "    test_image = image.load_img(new_image, target_size=(224, 224))\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(test_image)\n",
        "    plt.show()\n",
        "\n",
        "    test_image = image.img_to_array(test_image) / 255\n",
        "    test_image = np.expand_dims(test_image, axis=0)\n",
        "\n",
        "    predicted_array = model.predict(test_image)\n",
        "    predicted_value = output_class[np.argmax(predicted_array)]\n",
        "    predicted_accuracy = round(np.max(predicted_array) * 100, 2)\n",
        "\n",
        "    print(\"Your waste material is\", predicted_value, \"with\", predicted_accuracy, \"% accuracy.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34_xYk__luJc"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rn1YG5wTm1M0"
      },
      "outputs": [],
      "source": [
        "waste_prediction(\"/content/drive/MyDrive/Garbage_Classification_Project/Garbage-Classification-System/test_images/biological_biological212.jpg\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cB21Ed16m6ck"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(result.history[\"accuracy\"], label=\"Training Accuracy\", color='green')\n",
        "plt.title(\"Training Accuracy Over Epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFU4l1OLm_VR"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(result.history[\"loss\"], label=\"Training Loss\", color='red')\n",
        "plt.title(\"Training Loss Over Epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glqerDe5MNke"
      },
      "outputs": [],
      "source": [
        "model.save(\"/content/drive/MyDrive/waste_classifier_vgg16.keras\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXnofvT0OOLd"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model = load_model(\"/content/drive/MyDrive/waste_classifier_vgg16.keras\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "\n",
        "test_dir = \"test_images\"\n",
        "if os.path.exists(test_dir):\n",
        "    shutil.rmtree(test_dir)\n",
        "    print(\"üßπ Old test_images folder removed.\")\n",
        "\n",
        "os.makedirs(test_dir)\n",
        "print(\"‚úÖ New test_images folder created.\")\n",
        "\n",
        "# Step 3: Define class labels\n",
        "output_class = [\n",
        "    'battery', 'biological', 'brown-glass', 'cardboard', 'clothes',\n",
        "    'green-glass', 'metal', 'paper', 'plastic', 'shoes', 'trash', 'white-glass'\n",
        "]\n",
        "\n",
        "\n",
        "source_dir = \"/content/drive/MyDrive/Garbage_Classification_Project/Garbage-Classification-System/full_garbage_dataset/\"\n",
        "\n",
        "for cls in output_class:\n",
        "    class_path = os.path.join(source_dir, cls)\n",
        "\n",
        "    if not os.path.exists(class_path):\n",
        "        print(f\"‚ö†Ô∏è Skipped (folder not found): {cls}\")\n",
        "        continue\n",
        "\n",
        "    images = [img for img in os.listdir(class_path) if img.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "    for img_file in images[:5]:\n",
        "        src = os.path.join(class_path, img_file)\n",
        "        dst = os.path.join(test_dir, f\"{cls}_{img_file}\")\n",
        "        shutil.copy(src, dst)\n",
        "\n"
      ],
      "metadata": {
        "id": "lzvyBivLnQpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_OlGdNoOSZY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "test_dir = \"test_images\"\n",
        "\n",
        "test_images = []\n",
        "true_labels = []\n",
        "\n",
        "output_class = ['battery', 'biological', 'brown-glass', 'cardboard', 'clothes',\n",
        "                'green-glass', 'metal', 'paper', 'plastic', 'shoes', 'trash', 'white-glass']\n",
        "\n",
        "# Manual fallback label mapping\n",
        "label_map = {\n",
        "    \"brownglass\": \"brown-glass\",\n",
        "    \"greenglass\": \"green-glass\"\n",
        "}\n",
        "\n",
        "for file in os.listdir(test_dir):\n",
        "    if file.endswith(\".jpg\"):\n",
        "        test_images.append(file)\n",
        "        matched_label = None\n",
        "        # Try exact match from output_class\n",
        "        for cls in output_class:\n",
        "            if cls in file:\n",
        "                matched_label = cls\n",
        "                break\n",
        "        # Try fallback mapping if no match\n",
        "        if not matched_label:\n",
        "            for key, value in label_map.items():\n",
        "                if key in file:\n",
        "                    matched_label = value\n",
        "                    break\n",
        "        if matched_label:\n",
        "            true_labels.append(matched_label)\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è Skipped file (no label matched): {file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDzrEvczOgtT"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "predicted_labels = []\n",
        "\n",
        "for img_file in test_images:\n",
        "    img_path = os.path.join(test_dir, img_file)\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    pred = model.predict(img_array)\n",
        "    pred_class = output_class[np.argmax(pred)]\n",
        "    predicted_labels.append(pred_class)\n",
        "\n",
        "# üß† Check what was predicted and what was true\n",
        "print(\"‚úÖ True Labels:\", true_labels)\n",
        "print(\"üîÆ Predicted Labels:\", predicted_labels)\n",
        "\n",
        "# üìä Confusion Matrix\n",
        "cm = confusion_matrix(true_labels, predicted_labels, labels=output_class)\n",
        "\n",
        "plt.figure(figsize=(14, 10))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=output_class, yticklabels=output_class)\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# üìÑ Classification Report\n",
        "print(\"\\nüìã Classification Report:\\n\")\n",
        "print(classification_report(true_labels, predicted_labels, labels=output_class))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}